# To understand and implement the K-Nearest Neighbors (KNN) algorithm for solving classification problems using a structured, step-by-step approach.

# Tools Used

* Scikit-learn – for dataset loading, model building, and evaluation
* Pandas – for data handling
* Matplotlib – for plotting and visualizations

# Task Overview

# Dataset Selection and Normalization
  * Used the Iris dataset as the classification dataset.
  * Applied feature normalization using StandardScaler to bring all feature values to a similar scale.
# Model Building with KNeighborsClassifier
  * Implemented the KNN classifier using KNeighborsClassifier from Scikit-learn.
  * Trained the model using the training portion of the dataset.
# Experimented with Different Values of K
  * Tested multiple values of K (1 to 10).
  * Calculated and compared the accuracy for each K to determine the most effective one.
# Model Evaluation
  * Selected the best-performing K value.
  * Evaluated the classifier using accuracy score and confusion matrix. 
  * Displayed the confusion matrix for visual analysis of model performance.
# Visualized Decision Boundaries
  * Used only the first two features of the dataset for visualization.
  * Plotted decision boundaries to demonstrate how the KNN classifier separates different classes visually in 2D space.

# Dataset
Dataset Used: Iris Dataset

# Outcome
* Successfully implemented the KNN classification algorithm.
* Gained insight into how K values affect model accuracy.
* Visualized how KNN classifies data in a 2D feature space using decision boundaries.
